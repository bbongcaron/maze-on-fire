\documentclass[11pt]{article}
\usepackage{fancyhdr, extramarks, amsmath, amsthm, amsfonts, tikz, algpseudocode, graphicx, tcolorbox}
\usepackage[plain]{algorithm}
\graphicspath {{graphs/}}
\usetikzlibrary{automata,positioning}

\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in
\title{\textbf{Introduction to Artificial Intelligence\\
		\large Project 1: Maze on Fire}}
\author{Brenton Bongcaron and Abe Vitangcol\\NetIDs: bdb101 and alv88}
\date{February 19, 2021}
\begin{document}
	\maketitle
	\pagebreak
\section{Maze Generation}
The premise of the project is an agent being trapped in a maze. They start at the top left of the maze and need to get to the very bottom right of the maze. To create the maze environment, we created a function called buildMaze within maze.py which makes the maze in the form of a matrix.
\begin{verbatim}
def buildMaze(dim, p, firep=0):
    maze = [ [1 for col in range(dim)] for row in range(dim) ]
    # Randomly arranges obstacles
    fireTile = False
    for i in range(dim):
        for j in range(dim):
            rand = random()
            if rand <= p:
                maze[i][j] = 0
    # Randomly selects a fire tile
    while True:
        randx = randrange(dim)
        randy = randrange(dim)
        if maze[randx][randy] == 1 and randx != 0 and randx != (dim - 1)
        and randy != 0 and randy != (dim - 1):
            maze[randx][randy] = 2
            break
    # Ensure Start and Goal spaces are empty
    maze[0][0] = 1
    maze[dim - 1][dim - 1] = 1
    return maze

\end{verbatim}
Building the maze needs only a few requirements: the size of the maze (dim), and the obstacle density of the maze (p). The obstacle density is between 0 and 1, exclusive, and our code is ready to output an error message should a value be inputed outside that range. The maze is generated as a matrix with all of its entries, from (0,0) to (dim - 1, dim - 1), are 1. Then, going through each tile one by one using a nested for loop, we used random() as a way to randomize the maze, and if the value obtained from random() was less than or equal to the obstacle density, it became the obstacle, which means the value of the matrix at that coordinate was 0. When it finishes going through all of the tiles of the maze, we need to make sure that (0,0) and (dim - 1, dim - 1) are not obstacles, as they serve as the start and goal spaces, respectfully. So, we simply force these two spaces to be 1 (non-obstacle spaces) so the agent can be loaded in and is able to walk on top of the goal space.
The other part of this code is for the fire, which simply goes through the entire maze again until it has placed a space for the fire. If the space is a fire, then the maze at that point will equal two. Like the obstacles, if it was created on the start or goal spaces, it will be overwritten for a non-obstacle space.
	\pagebreak
\section{Finding the path to the goal: DFS}
For the first search algorithm, we were tasked at creating a Depth First Search algorithm and use it to help the agent navigate through the maze. To help us with creating this algorithm, we defined a helper function that says whether a move is valid or not, which we can use for both the DFS function as well as future functions too.
\begin{verbatim}
def isValid(maze, coordinate):
    if coordinate[0] < 0 or coordinate[0] >= len(maze) or
       coordinate[1] < 0 or coordinate[1] >= len(maze):
        return False
    if maze[coordinate[0]][coordinate[1]] == 1:
        return True
    return False
\end{verbatim}
Simply called isValid, located within maze.py, it takes in the current maze layout and the coordinate of interest. If the coordinate takes the agent out of bounds of the maze, then it returns false. If the coordinate of the maze is a free space, meaning the coordinate at that matrix location equals 1, then it returns true. There is a third false for fire scenarios, as the second if statement will be skipped as the fire tile is resembled as a 2 on the matrix, not a 1.

Using this, we created the DFS algorithm in maze.py and named it DFS.
\begin{verbatim}
def DFS(maze,start=(0,0),spacesTraveled=[], target=None):
    fringe = [start]
    visited = []
    for alreadyVisited in spacesTraveled:
        visited.append(alreadyVisited)
    prev = {start : None}
    if target is None:
        target = (len(maze) - 1, len(maze) - 1)
    start_time = time.time()
    while fringe:
        (currentRow, currentCol) = fringe.pop()
        ######################################
        # Check the children of currentState #
        ######################################
        if (currentRow, currentCol) == target:
            end_time = time.time()
            elapsed_time = end_time - start_time
            #print(str(elapsed_time) + "s to find path with DFS")
            return prev
        #upChild
        if isValid(maze, (currentRow - 1, currentCol)) and 
        (currentRow - 1, currentCol) not in visited:
            fringe.append((currentRow - 1, currentCol))
            prev.update({(currentRow - 1, currentCol) : (currentRow, currentCol)})
        #leftChild
        if isValid(maze, (currentRow, currentCol - 1)) and 
        (currentRow, currentCol - 1) not in visited:
            fringe.append((currentRow, currentCol - 1))
            prev.update({(currentRow, currentCol - 1) : (currentRow, currentCol)})
        #downChild
        if isValid(maze, (currentRow + 1, currentCol)) and 
        (currentRow + 1, currentCol) not in visited:
            fringe.append((currentRow + 1, currentCol))
            prev.update({(currentRow + 1, currentCol) : (currentRow, currentCol)})
        #rightChild
        if isValid(maze, (currentRow, currentCol + 1)) and 
        (currentRow, currentCol + 1) not in visited:
            fringe.append((currentRow, currentCol + 1))
            prev.update({(currentRow, currentCol + 1) : (currentRow, currentCol)})
        #########################################################################
        # Order (up,left,down,right) chosen so that any moves to the right or   #
        # down (closer to the Goal space, assuming no obstructions) are         # 
        # placed at the top of the stack and popped off before any moves up or  #
        # left.                                                                 #
        #########################################################################
        visited.append((currentRow, currentCol))
    return None
\end{verbatim}
This DFS algorithm requires the current layout of the maze, which is given as the parameter maze. The other three variables are default variables in which if a value is not specified upon calling the DFS function, it simply sets the start as (0,0), the target as nothing, and an empty list for the spacesTraveled. For the start and target, this is for any scenario in which the start and goal are not the typical (0,0) and (dim - 1, dim - 1), allowing flexibility for randomized spaces, if we want to. The spacesTraveled default variable is there for when the fire starts to spread and helps to with visualization when we run simulate.py or render.py.
The DFS algorithm examines the neighbors of the agent's node, with the agent's node called (currentRow, currentCol) in our code. The algorithm starts by pushing the current position of the agent into the stack, then later pops it, examining the popped node and seeing if the space is the goal. If so, it reports the time (currently commented out to save space in our command prompt) and returns the list of nodes the agent traveled through. If the popped node is not the goal space (always not so long as the dim value is greater than 1, which it always is), then it starts to check valid neighbors. It checks the north neighbor (called up child in our comments), the west neighbor (called left child), next the south neighbor (called down child), and finally the east neighbor (called the right child). They are pushed into the stack in this specific order as to prioritize going towards the goal (going either down or right) upon popping the next node. It constantly repeats this until it either has exhausted all nodes and hasn't gotten to the goal or until it reaches the goal.

Figure \ref{DFS_p_vs_successRate} shows a graph of the obstacle density vs the probability that S can be reached from G using our DFS algorithm and a maze size of $dim = 125$, with 100 unique maze runs being performed at each obstacle density, which increases by an interval of 0.2 after each set of 100 tests.

\begin{figure}[h]
\centering
\includegraphics[scale=0.55]{graphs/DFS_obstacleDensity_vs_successRate.PNG}
\caption{A plot of 'obstacle density $p$' vs 'probability that $S$ can be reached from $G$'.}
\label{DFS_p_vs_successRate}
\end{figure}

While a Breadth First Search (BFS) will find an optimal path in getting to the goal (assuming a path to the goal exists), DFS is actually better in a situation like this simply because we already know where the goal is from the start. By simply knowing where the goal is at the beginning of the run, we can simply beeline over to that destination by going down one whole branch to find the goal instead of going through all of the layers of a BFS tree just to eventually see the goal at the end of one of the branches. Simply put, using DFS in this maze is faster than BFS as BFS is always going a worst-case scenario in having to check majority of the nodes to find the goal, sometimes taking about 20 times longer than DFS. If the goal was randomized each run, then BFS would be a better pick as the goal would be somewhere in the middle of its tree rather than at the bottom while DFS would have to search entire branches one at a time to find the goal node somewhere in the middle.
	\pagebreak
\section{BFS and A* Implementation}
After completing the DFS search algorithm, it acted as a skeleton for other search algorithms, like BFS and A*, simply because all of them go through the same process, but they just have a different fringe or organizational method to proceed through the maze.
Both BFS and A* take in the same parameters as DFS, minus some unnecessary parameters such as the target or spacedTraveled. And they work relatively similarly to DFS.

\begin{verbatim}
def BFS(maze, start=(0,0), spacesTraveled=[]):
    fringe = [start]
    visited = []
    for alreadyVisited in spacesTraveled:
        visited.append(alreadyVisited)
    prev = {start : None}
    nodesExplored = 0
    start_time = time.time()
    while fringe:
        (currentRow, currentCol) = fringe.pop(0)
        nodesExplored += 1
        #takes off the first position coordinate off of fringe, acts as dequeue.
        #####################################
        # Checks the condition of the child #
        #####################################
        if (currentRow, currentCol) == (len(maze) - 1, len(maze) - 1):
            end_time = time.time()
            elapsed_time = end_time - start_time
            #print(str(elapsed_time) + "s to find path with DFS")
            return prev, nodesExplored
        #rightChild
        if isValid(maze, (currentRow, currentCol + 1)) and 
        ((currentRow, currentCol + 1) not in visited and 
        (currentRow, currentCol + 1) not in fringe):
            fringe.append((currentRow, currentCol + 1))
            prev.update({(currentRow, currentCol + 1) : (currentRow, currentCol)})
        #downChild
        if isValid(maze, (currentRow + 1, currentCol)) and 
        ((currentRow + 1, currentCol) not in visited and 
        (currentRow + 1, currentCol) not in fringe):
            fringe.append((currentRow + 1, currentCol))
            prev.update({(currentRow + 1, currentCol) : (currentRow, currentCol)})
        #leftChild
        if isValid(maze, (currentRow, currentCol - 1)) and 
        ((currentRow, currentCol - 1) not in visited and 
        (currentRow, currentCol - 1) not in fringe):
            fringe.append((currentRow, currentCol - 1))
            prev.update({(currentRow, currentCol - 1) : (currentRow, currentCol)})
        #upChild
        if isValid(maze, (currentRow - 1, currentCol)) and 
        ((currentRow - 1, currentCol) not in visited and 
        (currentRow - 1, currentCol) not in fringe):
            fringe.append((currentRow - 1, currentCol))
            prev.update({(currentRow - 1, currentCol) : (currentRow, currentCol)})
        #########################################################################
        # Order is (right, down, left, up), the reverse of the DFS. Chosen so   #
        # upon dequeuing (in this case fringe.pop(0)), it will prioritize going #
        # towards the goal per layer of the search before looking left or up.   #
        #########################################################################
        visited.append((currentRow, currentCol))
    return None, nodesExplored
\end{verbatim}

As seen here, the BFS code has a similar structure to DFS. The main difference is how the fringe is used. In DFS, the fringe acted as a stack, having the nodes being pushed in and popped. In BFS, the fringe acts as a queue. When a node is popped (doing fringe.pop(0) is the same as dequeueing), it is checked to see if it is the goal node or not. If so, it does what DFS does with little changes. If not, it checks the node's neighbors. In terms of the priority of searching its neighbors, it does right, then down, then left, then up, appending each one after checking if it's valid. It constantly repeats appending and popping(0) the fringe until it finds the goal, which takes significantly more time than DFS, even if it finds the most optimal path to the goal.

\begin{verbatim}
def aStar(maze, start=(0,0)):
    fringeNodes = [start]
    distances = [0]
    visited = []
    prev = {start: None}
    nodesExplored = 0
    start_time = time.time()
    while fringeNodes:
        # Find the node which has the lowest distance to the goal
        lowestDistance = min(distances)
        index = distances.index(lowestDistance)
        (currentRow, currentCol) = fringeNodes.pop(index)
        ####################### Visualize node just popped from fringe
        distances.pop(index)
        #######################
        nodesExplored += 1
        #####################################################################
        # Check the current condition of the child. If it's the goal, done. #
        # If not, find more children.                                       #
        #####################################################################
        if (currentRow, currentCol) == (len(maze) - 1, len(maze) - 1):
            end_time = time.time()
            elapsed_time = end_time - start_time
            return prev, nodesExplored
        # rightChild
        if isValid(maze, (currentRow, currentCol + 1)) and 
        ((currentRow, currentCol + 1) not in visited and 
        (currentRow, currentCol + 1) not in fringeNodes):
            x_squared = pow((len(maze) - 1) - (currentCol + 1), 2)
            y_squared = pow((len(maze) - 1) - (currentRow), 2)
            nodeDistance = math.sqrt(x_squared + y_squared)
            fringeNodes.append((currentRow, currentCol + 1))
            distances.append(nodeDistance)
            prev.update({(currentRow, currentCol + 1): (currentRow, currentCol)})
        # downChild
        if isValid(maze, (currentRow + 1, currentCol)) and 
        ((currentRow + 1, currentCol) not in visited and 
        (currentRow + 1, currentCol) not in fringeNodes):
            x_squared = pow((len(maze) - 1) - (currentCol), 2)
            y_squared = pow((len(maze) - 1) - (currentRow + 1), 2)
            nodeDistance = math.sqrt(x_squared + y_squared)
            fringeNodes.append((currentRow + 1, currentCol))
            distances.append(nodeDistance)
            prev.update({(currentRow + 1, currentCol): (currentRow, currentCol)})
        # leftChild
        if isValid(maze, (currentRow, currentCol - 1)) and 
        ((currentRow, currentCol - 1) not in visited and 
        (currentRow, currentCol - 1) not in fringeNodes):
            x_squared = pow((len(maze) - 1) - (currentCol - 1), 2)
            y_squared = pow((len(maze) - 1) - (currentRow), 2)
            nodeDistance = math.sqrt(x_squared + y_squared)
            fringeNodes.append((currentRow, currentCol - 1))
            distances.append(nodeDistance)
            prev.update({(currentRow, currentCol - 1): (currentRow, currentCol)})
        # upChild
        if isValid(maze, (currentRow - 1, currentCol)) and 
        ((currentRow - 1, currentCol) not in visited and 
        (currentRow - 1, currentCol) not in fringeNodes):
            x_squared = pow((len(maze) - 1) - (currentCol), 2)
            y_squared = pow((len(maze) - 1) - (currentRow - 1), 2)
            nodeDistance = math.sqrt(x_squared + y_squared)
            fringeNodes.append((currentRow - 1, currentCol))
            distances.append(nodeDistance)
            prev.update({(currentRow - 1, currentCol): (currentRow, currentCol)})
        visited.append((currentRow, currentCol))
    return None, nodesExplored
\end{verbatim}

The A* code (called aStar cause function declaration doesn't like asterisks) still maintains the structure of DFS. Like BFS, A*'s fringe performs differently as now it acts as a priority queue instead of a queue or a stack. Unlike the other two search algorithms, A* includes another array that records the cost and helps with doing priority queue actions. At first, when A* is called, it has a cost of 0 in distances (the helper priority queue) and the start node in the fringeNodes. A* finds the minimum in distances (done by doing min(distances)) and stores that value in the variable name lowestDistance. Next, we find the index at which this lowestDistance occurs in distances (by doing distances.index(lowestDistance)) and store that information in a variable called index. After obtaining the index of the lowest cost, we pop both priority queues at that index, with the value from fringeNodes being stored as (currentRow, currentCol) and the value from distances simply being lost.
Now that a node has been obtained, it goes through the same procedure as BFS and DFS, where it checks if the current node is the goal or not, reporting similar things should it be the goal node. When it checks for its neighbors, order doesn't technically matter, but we have it set to the same order as BFS. To calculate the distances, we simply use euclidean distance from the node in question (the right / left / down / up child) to the goal and record it in a variable called nodeDistance. Once calculated, we append the node in question to fringeNodes and append nodeDistance to distances at the same time in order to keep both of these items at the same index. After checking all the valid neighbors, A* goes back to the top and finds the minimum distance, finds its index, pops both the node at that index in fringeNodes and in distances, and goes back to checking neighbors again. This repeats until it reaches the goal and take much less time than BFS, although it does explore more nodes than it. 

Figure \ref{BFS-A} depicts the average number of nodes explored by BFS - number of nodes explored by A\text{*} vs obstacle density p at a size of \texttt{dim = 100}.

\begin{figure}[h]
\centering
\includegraphics[scale=0.55]{graphs/obstacleDensity_vs_nodesBFSminusNodesAstar.PNG}
\caption{A plot of 'obstacle density $p$' vs '\# nodes explored by BFS - \# nodes explored by A*'.}
\label{BFS-A}
\end{figure}

	\pagebreak
\section{Time is Everything}
The machine used for testing the maximum dimension of a maze that can be solved with DFS, BFS, and A* had the following specs:
\begin{itemize}
\item Intel(R) Core(TM) i7-4600M @2.90GHz
\item 8.00 GB RAM
\end{itemize}
The maximum dimension maze that could be solved in $<1$ min using DFS was 504 by 504.\\\\
The maximum dimension maze that could be solved in $<1$ min using A* was 511 by 511.\\

Since BFS clearly was going to reach a 1 minute time at a smaller dimension than DFS and A* and BFS notably explores more nodes layer by layer rather than probing a specific branch of children, we thought it would be worthwhile to explore the relationship between the dimension of the maze to be BFS'ed and the time elapsed to find the path to the goal.\\

\begin{figure}[h]
\centering
\includegraphics[scale=0.5]{dimVStimeBFS_MAX243.PNG}
\caption{A plot of maze dimension vs. time elapsed in seconds to find the goal with BFS}
\label{BFStime}
\end{figure}
The time it takes to find a path using BFS increases exponentially with respect to the dimension of the maze.

Plots were not generated for DFS and A* because the time elapsed to find the goal with these two algorithms is heavily dependent on probability. With DFS, the less the algorithm has to put children in the north or west directions into the fringe, the shorter the time it takes to find a path to the goal. With A*, the less the algorithm has to put children that are further away from the top left to bottom right diagonal into the fringe, the shorter the time it takes to find a path to the goal.
	\pagebreak
\section{This Maze is on Fi-yah: A New Strategy}
After completing the code for A* and BFS, now it is time to make things a bit more chaotic: set the maze on fire. Previously, there was code regarding the maze being on fire which was previously been brushed off to the side as we were not testing those scenarios yet. Now they become a bit more relevant.
	\pagebreak
\section{It's the Perfect Strategy: Just Don't Die}
In order to truly test the strategies, two helper codes are needed to see what happens during each strategy, both of which are seen in render.py. One is called movementOne which is the embodiment of strategy 1 in how, regardless of the search algorithm used, it will follow the path it found to the bitter end.

\begin{verbatim}
def movementOne(window, maze, firep, algorithm):
    dim = len(maze)
    spaceDim = size // dim
    # Starting agent location
    agentLocation = (0,0)
    # spacesTraveled - NOT NEEDED FOR STRATEGY 1
    # spacesTraveled = [agentLocation]
    prev = None
    if algorithm == "dfs":
        prev = DFS(maze, agentLocation)
    elif algorithm == "bfs":
        prev = BFS(maze, agentLocation)[0]
    elif algorithm == "a*":
        prev = aStar(maze, agentLocation)[0]
    elif algorithm == "a*+":
        prev = aStarPlus(maze, firep, agentLocation)[0]
    else:
        return False
    # The "Game loop"
    while True:
        currentSpace = (dim - 1, dim - 1)
        # If no more paths to goal are present, stop NOT NEEDED FOR STRATEGY 1
        #if prev is None:
            #return False
        # While loop to find the next move for the agent
        while prev[currentSpace] != agentLocation:
            currentSpace = prev[currentSpace]
        # Color the previous space gray
        prevSpace = pygame.Rect(prev[currentSpace][1]*spaceDim, 
        			prev[currentSpace][0]*spaceDim, spaceDim, spaceDim)
        pygame.draw.rect(window, (150, 150, 150), prevSpace, width=0)
        pygame.draw.rect(window, (0,0,0), prevSpace, width=1)
        pygame.display.update()
        # Color the agent's new location blue
        newCurrent = pygame.Rect(currentSpace[1]*spaceDim,
        			currentSpace[0]*spaceDim, spaceDim,  spaceDim)
        pygame.draw.rect(window, (0,0,255), newCurrent, width=0)
        pygame.draw.rect(window, (0,0,0), newCurrent, width=1)
        pygame.display.update()
        # Update spacesTraveled and the agent's new location NOT NEEDED FOR STRATEGY 1
        #spacesTraveled.append(currentSpace)
        agentLocation = currentSpace
        ####################################################################
        #   Fire spread
        ####################################################################
        maze, newFires = fireSpread(maze, firep)
        # Color new fire spaces red
        for space in newFires:
            newFire = pygame.Rect(space[1]*spaceDim, 
            			space[0]*spaceDim, spaceDim, spaceDim)
            pygame.draw.rect(window, (255,0,0), newFire, width=0)
            pygame.draw.rect(window, (0,0,0), newFire, width=1)
            pygame.display.update()
        time.sleep(sleepTime)
        # Agent dies if it catches on fire
        if maze[agentLocation[0]][agentLocation[1]] == 2:
            return False
        # Return if at the Goal
        if agentLocation == (dim - 1, dim - 1):
            return True
\end{verbatim}

The other is called movementTwo, which, well guessed, is the embodiment of strategy 2 in how the search algorithm used (DFS, BFS, A*) recalculates its path based on the current fire's position and redirects the path if it needs to.

\begin{verbatim}
def movementTwo(window, maze, firep, algorithm):
    dim = len(maze)
    spaceDim = size // dim
    # Starting agent location
    agentLocation = (0,0)
    # spacesTraveled - A dynamic visited list to be passed to DFS
    spacesTraveled = [agentLocation]
    # The "Game loop"
    while True:
        prev = None
        if algorithm == "dfs":
            prev = DFS(maze, agentLocation, spacesTraveled)
        elif algorithm == "bfs":
            prev = BFS(maze, agentLocation, spacesTraveled)[0]
        elif algorithm == "a*":
            prev = aStar(maze, agentLocation)[0]
        elif algorithm == "a*+":
            prev = aStarPlus(maze, firep, agentLocation, spacesTraveled)[0]
        else:
            return False
        currentSpace = (dim - 1, dim - 1)
        # If no more paths to goal are present, stop
        if prev is None:
            return False
        # While loop to find the next move for the agent
        while prev[currentSpace] != agentLocation:
            currentSpace = prev[currentSpace]
        # Color the previous space gray
        #prevSpace = pygame.Rect(prev[currentSpace][1]*spaceDim,
        			prev[currentSpace][0]*spaceDim, spaceDim, spaceDim)
        #pygame.draw.rect(window, (150, 150, 150), prevSpace, width=0)
        #pygame.draw.rect(window, (0,0,0), prevSpace, width=1)
        #pygame.display.update()
        # Color the agent's new location blue
        #newCurrent = pygame.Rect(currentSpace[1]*spaceDim,
        			currentSpace[0]*spaceDim, spaceDim,  spaceDim)
        #pygame.draw.rect(window, (0,0,255), newCurrent, width=0)
        #pygame.draw.rect(window, (0,0,0), newCurrent, width=1)
        #pygame.display.update()
        # Update spacesTraveled and the agent's new location
        spacesTraveled.append(currentSpace)
        agentLocation = currentSpace
        ####################################################################
        #   Fire spread
        ####################################################################
        maze, newFires = fireSpread(maze, firep)
        # Color new fire spaces red
        #for space in newFires:
            #newFire = pygame.Rect(space[1]*spaceDim, 
            			space[0]*spaceDim, spaceDim, spaceDim)
            #pygame.draw.rect(window, (255,0,0), newFire, width=0)
            #pygame.draw.rect(window, (0,0,0), newFire, width=1)
            #pygame.display.update()
        time.sleep(sleepTime)
        # Agent dies if it catches on fire
        if agentLocation in newFires:
            return False
        # Return if at the Goal
        if agentLocation == (dim - 1, dim - 1):
            return True
\end{verbatim}

With these two helper codes, we can test both Strategy 1 and 2 using whatever search algorithm we want. However, we also need to test our Strategy 3 of (INSERT STRATEGY 3 CONTENTS HERE). Below are the graphs of the extensive testing performed using these strategies.
\begin{figure}[!]
\centering
\includegraphics[scale=0.50]{Strategy1_q_successRate.PNG}
\caption{A graph of 'flammability rate q' vs 'strategy success rate' at $p = 0.3$ w/Strategy 1}
\includegraphics[scale=0.50]{Strategy2_q_successRate.PNG}
\caption{A graph of 'flammability rate q' vs 'strategy success rate' at $p = 0.3$ w/Strategy 2}
\end{figure}
\begin{figure}[!]
\centering
\includegraphics[scale=0.50]{Strategy3_q_successRate.PNG}
\caption{A graph of 'flammability rate q' vs 'strategy success rate' at $p = 0.3$ w/Strategy 3}
\end{figure}

\pagebreak
\section{Theoretical Analysis: Unlimited Computational Power}
Answer here
	\pagebreak
\section{There is No Time to Slack}
Answer here
	\pagebreak
\section{Notable Information}
Additional things / for fun thing go here
\end{document}